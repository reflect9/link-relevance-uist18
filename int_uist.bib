@article{cer_2018,
	author = {{Cer}, D. and {Yang}, Y. and {Kong}, S.-y. and {Hua}, N. and 
	{Limtiaco}, N. and {St.~John}, R. and {Constant}, N. and {Guajardo-Cespedes}, M. and 
	{Yuan}, S. and {Tar}, C. and {Sung}, Y.-H. and {Strope}, B. and 
	{Kurzweil}, R.},
	title = "{Universal Sentence Encoder}",
	journal = {ArXiv e-prints},
	archivePrefix = "arXiv",
	eprint = {1803.11175},
	primaryClass = "cs.CL",
	keywords = {Computer Science - Computation and Language},
	year = 2018,
	month = mar,
	adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180311175C},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{kingma_2014,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  journal   = {CoRR},
  volume    = {abs/1412.6980},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.6980},
  archivePrefix = {arXiv},
  eprint    = {1412.6980},
  timestamp = {Wed, 07 Jun 2017 14:40:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KingmaB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{szegedy_2015,
  author    = {Christian Szegedy and
               Vincent Vanhoucke and
               Sergey Ioffe and
               Jonathon Shlens and
               Zbigniew Wojna},
  title     = {Rethinking the Inception Architecture for Computer Vision},
  journal   = {CoRR},
  volume    = {abs/1512.00567},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.00567},
  archivePrefix = {arXiv},
  eprint    = {1512.00567},
  timestamp = {Wed, 07 Jun 2017 14:40:22 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SzegedyVISW15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{smith_2007,
title = {An Overview of the Tesseract OCR Engine},
author  = {Ray Smith},
year  = {2007},
booktitle = {Proc. Ninth Int. Conference on Document Analysis and Recognition (ICDAR)},
pages = {629--633}
}

@misc{noauthor_computer_2011,
	title = {Computer {Vision} at {Western} - {Code}},
	url = {http://vision.csd.uwo.ca/code/},
	urldate = {2011-05-12},
	month = may,
	year = {2011},
	file = {Computer Vision at Western - Code:/Users/talee/Zotero/storage/2DNBRZQC/code.html:text/html}
}

@article{arbelaez_contour_2010,
	title = {Contour {Detection} and {Hierarchical} {Image} {Segmentation}},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Arbeláez, P. and Maire, M. and Fowlkes, C. and Malik, J.},
	year = {2010},
	file = {amfm_pami2010.pdf:/Users/talee/Zotero/storage/EUNABNJE/amfm_pami2010.pdf:application/pdf}
}

@misc{noauthor_notitle_nodate
}

@misc{noauthor_exact_nodate,
	title = {Exact maximum a posteriori estimation for binary images {\textbar} {Mendeley}},
	url = {http://www.mendeley.com/research/exact-maximum-a-posteriori-estimation-for-binary-images/},
	urldate = {2011-05-12},
	file = {Exact maximum a posteriori estimation for binary images | Mendeley:/Users/talee/Zotero/storage/9PJTTG49/exact-maximum-a-posteriori-estimation-for-binary-images.html:text/html}
}

@inproceedings{gemmell_mylifebits:_2002,
	title = {{MyLifeBits}: fulfilling the {Memex} vision},
	isbn = {1-58113-620-X},
	shorttitle = {{MyLifeBits}},
	booktitle = {Proceedings of the tenth {ACM} international conference on {Multimedia}},
	author = {Gemmell, J. and Bell, G. and Lueder, R. and Drucker, S. and Wong, C.},
	year = {2002},
	pages = {235--238},
	file = {p121-park.pdf:/Users/talee/Zotero/storage/H9GAWNPP/p121-park.pdf:application/pdf}
}

@inproceedings{gemmell_mylifebits:_2002-1,
	title = {{MyLifeBits}: fulfilling the {Memex} vision},
	isbn = {1-58113-620-X},
	shorttitle = {{MyLifeBits}},
	booktitle = {Proceedings of the tenth {ACM} international conference on {Multimedia}},
	author = {Gemmell, J. and Bell, G. and Lueder, R. and Drucker, S. and Wong, C.},
	year = {2002},
	pages = {235--238},
	file = {p121-park.pdf:/Users/talee/Zotero/storage/AW63WX6T/p121-park.pdf:application/pdf}
}

@misc{noauthor_growing_2015,
	title = {The growing problem of {Internet} “link rot” and best practices for media and online publishers},
	url = {https://journalistsresource.org/studies/society/internet/website-linking-best-practices-media-online-publishers},
	abstract = {Ten linking “best practices,” with an emphasis on stability and transparency. The goal is to reduce the chance that links will go bad, minimize the work going forward and maximize the utility for users.},
	language = {en-US},
	urldate = {2018-01-14},
	journal = {Journalist's Resource},
	month = oct,
	year = {2015},
	file = {Snapshot:/Users/talee/Zotero/storage/NPWDEEY7/website-linking-best-practices-media-online-publishers.html:text/html}
}

@article{hennessey_cross_2013,
	title = {A cross disciplinary study of link decay and the effectiveness of mitigation techniques},
	volume = {14},
	issn = {1471-2105},
	url = {https://doi.org/10.1186/1471-2105-14-S14-S5},
	doi = {10.1186/1471-2105-14-S14-S5},
	abstract = {The dynamic, decentralized world-wide-web has become an essential part of scientific research and communication. Researchers create thousands of web sites every year to share software, data and services. These valuable resources tend to disappear over time. The problem has been documented in many subject areas. Our goal is to conduct a cross-disciplinary investigation of the problem and test the effectiveness of existing remedies.},
	number = {14},
	journal = {BMC Bioinformatics},
	author = {Hennessey, Jason and Ge, Steven Xijin},
	month = oct,
	year = {2013},
	pages = {S5}
}

@article{zittrain_perma:_2014,
	title = {Perma: {Scoping} and {Addressing} the {Problem} of {Link} and {Reference} {Rot} in {Legal} {Citations}},
	volume = {14},
	issn = {1472-6696, 1741-2021},
	shorttitle = {Perma},
	url = {https://www.cambridge.org/core/journals/legal-information-management/article/perma-scoping-and-addressing-the-problem-of-link-and-reference-rot-in-legal-citations/15A59548BF9882B06D3064DA7E290859},
	doi = {10.1017/S1472669614000255},
	abstract = {AbstractIt has become increasingly common for a reader to follow a URL cited in a court opinion or a law review article, only to be met with an error message because the resource has been moved from its original online address. This form of reference rot, commonly referred to as ‘linkrot’, has arisen from the disconnect between the transience of online materials and the permanence of legal citation, and will only become more prevalent as scholarly materials move online. The present paper*, written by Jonathan Zittrain, Kendra Albert and Lawrence Lessig, explores the pervasiveness of linkrot in academic and legal citations, finding that more than 70\% of the URLs within the Harvard Law Review and other journals, and 50\% of the URLs within United States Supreme Court opinions, do not link to the originally cited information. In light of these results, a solution is proposed for authors and editors of new scholarship that involves libraries undertaking the distributed, long-term preservation of link contents.},
	language = {en},
	number = {2},
	urldate = {2018-01-14},
	journal = {Legal Information Management},
	author = {Zittrain, Jonathan and Albert, Kendra and Lessig, Lawrence},
	month = jun,
	year = {2014},
	keywords = {legal citations, link rot, web archiving, websites},
	pages = {88--99},
	file = {Snapshot:/Users/talee/Zotero/storage/GMRQ9RPT/15A59548BF9882B06D3064DA7E290859.html:text/html}
}

@inproceedings{bar-yossef_sic_2004,
	title = {Sic {Transit} {Gloria} {Telae}: {Towards} an {Understanding} of the {Web}'s {Decay}},
	booktitle = {In {Proceedings} of the 13th conference on {World} {Wide} {Web}},
	publisher = {ACM Press},
	author = {Bar-yossef, Ziv and Kumar, Ravi and Broder, Andrei Z. and Tomkins, Andrew},
	year = {2004},
	pages = {328--337}
}

@inproceedings{fetterly_large-scale_2003,
	address = {New York, NY, USA},
	series = {{WWW} '03},
	title = {A {Large}-scale {Study} of the {Evolution} of {Web} {Pages}},
	isbn = {978-1-58113-680-7},
	url = {http://doi.acm.org/10.1145/775152.775246},
	doi = {10.1145/775152.775246},
	abstract = {How fast does the web change? Does most of the content remain unchanged once it has been authored, or are the documents continuously updated? Do pages change a little or a lot? Is the extent of change correlated to any other property of the page? All of these questions are of interest to those who mine the web, including all the popular search engines, but few studies have been performed to date to answer them.One notable exception is a study by Cho and Garcia-Molina, who crawled a set of 720,000 pages on a daily basis over four months, and counted pages as having changed if their MD5 checksum changed. They found that 40\% of all web pages in their set changed within a week, and 23\% of those pages that fell into the .com domain changed daily.This paper expands on Cho and Garcia-Molina's study, both in terms of coverage and in terms of sensitivity to change. We crawled a set of 150,836,209 HTML pages once every week, over a span of 11 weeks. For each page, we recorded a checksum of the page, and a feature vector of the words on the page, plus various other data such as the page length, the HTTP status code, etc. Moreover, we pseudo-randomly selected 0.1\% of all of our URLs, and saved the full text of each download of the corresponding pages.After completion of the crawl, we analyzed the degree of change of each page, and investigated which factors are correlated with change intensity. We found that the average degree of change varies widely across top-level domains, and that larger pages change more often and more severely than smaller ones.This paper describes the crawl and the data transformations we performed on the logs, and presents some statistical observations on the degree of change of different classes of pages.},
	urldate = {2018-01-14},
	booktitle = {Proceedings of the 12th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Fetterly, Dennis and Manasse, Mark and Najork, Marc and Wiener, Janet},
	year = {2003},
	keywords = {degree of change, rate of change, web characterization, web evolution, web pages},
	pages = {669--678},
	file = {ACM Full Text PDF:/Users/talee/Zotero/storage/AUYUCCUC/Fetterly et al. - 2003 - A Large-scale Study of the Evolution of Web Pages.pdf:application/pdf}
}

@misc{noauthor_only_nodate,
	title = {The {Only} {URL} {Shortener} \& {Link} {Cloaker} {You}'ll {Ever} {Need}},
	url = {https://prettylinks.com/?aff=wordpress},
	urldate = {2018-01-19},
	file = {The Only URL Shortener & Link Cloaker You'll Ever Need:/Users/talee/Zotero/storage/WV5EBBKY/prettylinks.com.html:text/html}
}

@article{mason_conducting_2012,
	title = {Conducting behavioral research on {Amazon}’s {Mechanical} {Turk}},
	volume = {44},
	issn = {1554-3528},
	url = {https://link.springer.com/article/10.3758/s13428-011-0124-6},
	doi = {10.3758/s13428-011-0124-6},
	abstract = {Amazon’s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.},
	language = {en},
	number = {1},
	urldate = {2018-02-21},
	journal = {Behavior Research Methods},
	author = {Mason, Winter and Suri, Siddharth},
	month = mar,
	year = {2012},
	pages = {1--23},
	file = {Full Text PDF:/Users/talee/Zotero/storage/YE4TP3Q2/Mason and Suri - 2012 - Conducting behavioral research on Amazon’s Mechani.pdf:application/pdf;Snapshot:/Users/talee/Zotero/storage/ZYUZH566/s13428-011-0124-6.html:text/html}
}

@article{de_boom_representation_2016,
	title = {Representation {Learning} for {Very} {Short} {Texts} {Using} {Weighted} {Word} {Embedding} {Aggregation}},
	volume = {80},
	issn = {0167-8655},
	url = {https://doi.org/10.1016/j.patrec.2016.06.012},
	doi = {10.1016/j.patrec.2016.06.012},
	abstract = {We create text representations by weighing word embeddings using idf information.A novel median-based loss is designed to mitigate the negative effect of outliers.A dataset of semantically related textual pairs from Wikipedia and Twitter is made.Our method outperforms all word embedding baselines in a semantic similarity task.Our method is out-of-the-box and thus requires no retraining in different contexts. Short text messages such as tweets are very noisy and sparse in their use of vocabulary. Traditional textual representations, such as tf-idf, have difficulty grasping the semantic meaning of such texts, which is important in applications such as event detection, opinion mining, news recommendation, etc. We constructed a method based on semantic word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. For this purpose we designed a weight-based model and a learning procedure based on a novel median-based loss function. This paper discusses the details of our model and the optimization methods, together with the experimental results on both Wikipedia and Twitter data. We find that our method outperforms the baseline approaches in the experiments, and that it generalizes well on different word embeddings without retraining. Our method is therefore capable of retaining most of the semantic information in the text, and is applicable out-of-the-box.},
	number = {C},
	urldate = {2018-03-28},
	journal = {Pattern Recogn. Lett.},
	author = {De Boom, Cedric and Van Canneyt, Steven and Demeester, Thomas and Dhoedt, Bart},
	month = sep,
	year = {2016},
	keywords = {Artificial intelligence, Information storage and retrieval, Natural language processing, Representation learning, Word embeddings},
	pages = {150--156}
}

@inproceedings{Lee_Misalignments_2018,
 author = {Lee, Tak Yeon and Koh, Eunyee},
 title = {Identifying Types of Misalignments between Promotion Emails and Landing Pages},
 booktitle = {CHI '18 Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '18},
 year = {2018},
 isbn = {978-1-4503-5621-3/18/04},
 location = {Montreal, Canada},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/3170427.3188682},
 doi = {10.1145/3170427.3188682},
 publisher = {ACM},
 address = {New York, NY, USA}
} 

@inproceedings{chakrabarti2008contextual,
  title={Contextual advertising by combining relevance with click feedback},
  author={Chakrabarti, Deepayan and Agarwal, Deepak and Josifovski, Vanja},
  booktitle={Proceedings of the 17th international conference on World Wide Web},
  pages={417--426},
  year={2008},
  organization={ACM}
}

@inproceedings{regelson2006predicting,
  title={Predicting Click-Through Rate Using Keyword Clusters},
  author={Regelson, Moira and Fain, Daniel C},
  booktitle={EC’06, SSA2 JUNE 11, 2006, ANN ARBOR, MI.},
  year={2006},
  organization={Citeseer}
}
@inproceedings{Becker:2009:HAA:1645953.1645964,
 author = {Becker, Hila and Broder, Andrei and Gabrilovich, Evgeniy and Josifovski, Vanja and Pang, Bo},
 title = {What Happens After an Ad Click?: Quantifying the Impact of Landing Pages in Web Advertising},
 booktitle = {Proceedings of the 18th ACM Conference on Information and Knowledge Management},
 series = {CIKM '09},
 year = {2009},
 isbn = {978-1-60558-512-3},
 location = {Hong Kong, China},
 pages = {57--66},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1645953.1645964},
 doi = {10.1145/1645953.1645964},
 acmid = {1645964},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {landing page taxonomy, online advertising},
} 
@inproceedings{Rosales:2012:PCM:2124295.2124333,
 author = {Rosales, R\'{o}mer and Cheng, Haibin and Manavoglu, Eren},
 title = {Post-click Conversion Modeling and Analysis for Non-guaranteed Delivery Display Advertising},
 booktitle = {Proceedings of the Fifth ACM International Conference on Web Search and Data Mining},
 series = {WSDM '12},
 year = {2012},
 isbn = {978-1-4503-0747-5},
 location = {Seattle, Washington, USA},
 pages = {293--302},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2124295.2124333},
 doi = {10.1145/2124295.2124333},
 acmid = {2124333},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {conversion modeling, conversion rate, display advertising, non-guaranteed delivery, post-click conversion},
} 

@inproceedings{huang2008similarity,
  title={Similarity measures for text document clustering},
  author={Huang, Anna},
  booktitle={Proceedings of the sixth new zealand computer science research student conference (NZCSRSC2008), Christchurch, New Zealand},
  pages={49--56},
  year={2008}
}
@inproceedings{lukashenko2007computer,
  title={Computer-based plagiarism detection methods and tools: an overview},
  author={Lukashenko, Romans and Graudina, Vita and Grundspenkis, Janis},
  booktitle={Proceedings of the 2007 international conference on Computer systems and technologies},
  pages={40},
  year={2007},
  organization={ACM}
}

@InProceedings{rebervsek-verlic:2013:EMNLP,
  author    = {Reber\v{s}ek, Peter  and  Verlic, Mateja},
  title     = {Application of Localized Similarity for Web Documents},
  booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
  month     = {October},
  year      = {2013},
  address   = {Seattle, Washington, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {1399--1404},
  url       = {http://www.aclweb.org/anthology/D13-1142}
}



@inproceedings{Gong:2017:MLW:3123266.3123296,
 author = {Gong, Dihong and Wang, Daisy Zhe and Peng, Yang},
 title = {Multimodal Learning for Web Information Extraction},
 booktitle = {Proceedings of the 2017 ACM on Multimedia Conference},
 series = {MM '17},
 year = {2017},
 isbn = {978-1-4503-4906-2},
 location = {Mountain View, California, USA},
 pages = {288--296},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3123266.3123296},
 doi = {10.1145/3123266.3123296},
 acmid = {3123296},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {information extraction, multimodal, web mining},
} 


@inproceedings{Bylinskii:2017:LVI:3126594.3126653,
 author = {Bylinskii, Zoya and Kim, Nam Wook and O'Donovan, Peter and Alsheikh, Sami and Madan, Spandan and Pfister, Hanspeter and Durand, Fredo and Russell, Bryan and Hertzmann, Aaron},
 title = {Learning Visual Importance for Graphic Designs and Data Visualizations},
 booktitle = {Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology},
 series = {UIST '17},
 year = {2017},
 isbn = {978-1-4503-4981-9},
 location = {Qu\&\#233;bec City, QC, Canada},
 pages = {57--69},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3126594.3126653},
 doi = {10.1145/3126594.3126653},
 acmid = {3126653},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computer vision, deep learning, eye tracking, graphic design, machine learning, retargeting, saliency, visualization},
} 
[download]